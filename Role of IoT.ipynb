{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries to run the code\n",
    "import re,string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import keras_metrics\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "#from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Cleaned-Data.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_columns = df.filter(like='Severity_').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Severity_None'].replace({1:'None',0:'No'},inplace =True)\n",
    "df['Severity_Mild'].replace({1:'Mild',0:'No'},inplace =True)\n",
    "df['Severity_Moderate'].replace({1:'Moderate',0:'No'},inplace =True)\n",
    "df['Severity_Severe'].replace({1:'Severe',0:'No'},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition']=df[severity_columns].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing(list1):\n",
    "    list1 = set(list1) \n",
    "    list1.discard(\"No\")\n",
    "    a = ''.join(list1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition'] = df['Condition'].apply(removing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_columns = df.filter(like='Age_').columns\n",
    "gender_columns = df.filter(like='Gender_').columns\n",
    "contact_columns = df.filter(like='Contact_').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_risk_age = df.groupby(['Severity_None'])[age_columns].sum()\n",
    "No_risk_gender = df.groupby(['Severity_None'])[gender_columns].sum()\n",
    "No_risk_contact = df.groupby(['Severity_None'])[contact_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Low_risk_age = df.groupby(['Severity_Mild'])[age_columns].sum()\n",
    "Low_risk_gender = df.groupby(['Severity_Mild'])[gender_columns].sum()\n",
    "Low_risk_contact = df.groupby(['Severity_Mild'])[contact_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moderate_risk_age = df.groupby(['Severity_Moderate'])[age_columns].sum()\n",
    "Moderate_risk_gender = df.groupby(['Severity_Moderate'])[gender_columns].sum()\n",
    "Moderate_risk_contact = df.groupby(['Severity_Moderate'])[contact_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Severe_risk_age = df.groupby(['Severity_Severe'])[age_columns].sum()\n",
    "Severe_risk_gender = df.groupby(['Severity_Severe'])[gender_columns].sum()\n",
    "Severe_risk_contact = df.groupby(['Severity_Severe'])[contact_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Country\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(severity_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Symptoms_Score'] = df.iloc[:,:5].sum(axis=1) + df.iloc[:,6:10].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['Condition'] = le.fit_transform(df['Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 13, 18\n",
    "corrmat = df.corr()\n",
    "k = 22\n",
    "cols = corrmat.nlargest(k, 'Condition')['Condition'].index\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(['Condition'],axis=1)\n",
    "y= df['Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Muhammad Umer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23953598484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.17      0.20     15975\n",
      "           1       0.25      0.11      0.15     15909\n",
      "           2       0.24      0.33      0.28     15757\n",
      "           3       0.24      0.35      0.29     15719\n",
      "\n",
      "    accuracy                           0.24     63360\n",
      "   macro avg       0.24      0.24      0.23     63360\n",
      "weighted avg       0.24      0.24      0.23     63360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "lr=LogisticRegression()\n",
    "print(\"Logistic Regression Result\")\n",
    "logisticRegresion=lr.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,logisticRegresion))\n",
    "print(classification_report(y_test,logisticRegresion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Classifier\n",
      "0.2399621212121212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.20      0.22     15975\n",
      "           1       0.24      0.14      0.18     15909\n",
      "           2       0.24      0.29      0.26     15757\n",
      "           3       0.24      0.33      0.28     15719\n",
      "\n",
      "    accuracy                           0.24     63360\n",
      "   macro avg       0.24      0.24      0.23     63360\n",
      "weighted avg       0.24      0.24      0.23     63360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print(\"Bernoulli Naive Bayes Classifier\")\n",
    "gnb = BernoulliNB()\n",
    "predictionBNB=gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test,predictionBNB))\n",
    "print(classification_report(y_test,predictionBNB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
